/*
 * Copyright Debezium Authors.
 *
 * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
 */
package io.debezium.embedded;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.CompletableFuture;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executor;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeoutException;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicLong;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.Function;

import org.apache.kafka.common.config.ConfigDef;
import org.apache.kafka.common.config.ConfigDef.Importance;
import org.apache.kafka.common.config.ConfigDef.Type;
import org.apache.kafka.common.config.ConfigDef.Width;
import org.apache.kafka.connect.connector.ConnectorContext;
import org.apache.kafka.connect.connector.Task;
import org.apache.kafka.connect.data.Struct;
import org.apache.kafka.connect.json.JsonConverter;
import org.apache.kafka.connect.runtime.WorkerConfig;
import org.apache.kafka.connect.runtime.distributed.DistributedConfig;
import org.apache.kafka.connect.runtime.standalone.StandaloneConfig;
import org.apache.kafka.connect.source.SourceConnector;
import org.apache.kafka.connect.source.SourceRecord;
import org.apache.kafka.connect.source.SourceTask;
import org.apache.kafka.connect.source.SourceTaskContext;
import org.apache.kafka.connect.storage.Converter;
import org.apache.kafka.connect.storage.FileOffsetBackingStore;
import org.apache.kafka.connect.storage.KafkaOffsetBackingStore;
import org.apache.kafka.connect.storage.OffsetBackingStore;
import org.apache.kafka.connect.storage.OffsetStorageReader;
import org.apache.kafka.connect.storage.OffsetStorageReaderImpl;
import org.apache.kafka.connect.storage.OffsetStorageWriter;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import io.debezium.annotation.Immutable;
import io.debezium.annotation.ThreadSafe;
import io.debezium.config.Configuration;
import io.debezium.config.Field;
import io.debezium.config.InvalidConfigurationException;
import io.debezium.consumer.ChangeEvent;
import io.debezium.consumer.EventService;
import io.debezium.consumer.EventStream;
import io.debezium.util.Clock;
import io.debezium.util.Threads;

/**
 * An {@link EventService} that runs one or more Debezium connectors and allows the application to directly consume the
 * events produced by the connectors.
 * <p>
 * <h2>Class loaders</h2>
 * <p>
 * When you create a ConnectorEngine, you can optionally provide a class loader that the engine will use as a default for
 * each of the connectors. If none is provided the engine will simply use the same class loader that loaded the ConnectorEngine
 * class.
 * <p>
 * You can also provide a class loader when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) adding} each
 * connector, and the engine will then use that class loader to load the connector's classes.
 * <p>
 * <h2>Callbacks</h2>
 * <p>
 * The engine logs very little information, so all feedback as to when the connectors and tasks start, stop, or fail are
 * sent through <em>callbacks</em> that are provided when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader)
 * defining} connectors. The {@link ConnectorCallback} interface has methods that include the connector name, so the same
 * callback object can be used for multiple connectors.
 * <p>
 * <h2>Consuming events</h2>
 * <p>
 * Each connector engine provides a single {@link EventStream} of all events generated by the deployed connectors.
 * The {@link #poll(long, TimeUnit)} method is the primary means of accessing these events, and each list of events returned
 * by this method will contain events from a single connector. The engine will provide back-pressure on the connectors
 * should the events not be consumed as quickly as they are produced, and this back-pressure can be controlled by
 * adjusting the {@link #MAX_QUEUE_SIZE size of the engine's queue}.
 * <p>
 * However, reading the events from the stream does not mean that the consuming application has completely processed or consumed
 * that event. Instead, the consuming application is expected to consume them in the same order in which they are read
 * and is <b>required</b> to call {@link ChangeEvent#commit()} on every event when it has been fully processed. Only when this
 * is done will the engine record the <em>offset</em> for the event, so that upon restart previously committed events
 * will not be seen again.
 * <p>
 * <h2>Offsets</h2>
 * <p>
 * The engine records offsets in an <em>offset store</em> defined in the engine's configuration, and two stores are available
 * out of the box. The first is a {@link FileOffsetBackingStore} that stores all offsets for all connectors in a single local
 * file, and the application running the engine is expected to ensure this file is available and persisted properly.
 * The second is the {@link KafkaOffsetBackingStore} that stores all offsets for all connectors in a Kafka topic, which provides
 * more durable storage assuming the Kafka broker is replicated sufficiently. Of course any {@link OffsetBackingStore}
 * implementation can be used.
 * 
 * @author Randall Hauch
 */
public class ConnectorEngine implements EventStream {

    /**
     * A required field for each connector.
     */
    public static final Field CONNECTOR_NAME = Field.create("name")
                                                    .withType(Type.STRING)
                                                    .withImportance(Importance.HIGH)
                                                    .withWidth(Width.MEDIUM)
                                                    .withValidation(Field::isRequired);

    /**
     * A required field for an embedded connector that specifies the name of the normal Debezium connector's Java class.
     */
    public static final Field CONNECTOR_CLASS = Field.create("connector.class")
                                                     .withDescription("The Java class for the connector")
                                                     .withValidation(Field::isRequired);

    /**
     * A required field for an embedded connector that specifies the name of the normal Debezium connector's Java class.
     */
    public static final Field CONNECTOR_TASKS_MAX = Field.create("task.max")
                                                         .withType(Type.INT)
                                                         .withDefault(1)
                                                         .withImportance(Importance.MEDIUM)
                                                         .withWidth(Width.MEDIUM)
                                                         .withValidation(Field::isRequired)
                                                         .withDescription("The maximum number of tasks that should be created for this connector. The connector may create fewer tasks if it cannot achieve this level of parallelism.");

    /**
     * The minimal set of fields that are required by each connectors.
     */
    public static final Field.Set CONNECTOR_FIELDS = Field.setOf(CONNECTOR_NAME, CONNECTOR_CLASS, CONNECTOR_TASKS_MAX);

    /**
     * A required field for the {@link ConnectorEngine} object.
     */
    public static final Field NAME = Field.create("name")
                                          .withType(Type.STRING)
                                          .withImportance(Importance.HIGH)
                                          .withWidth(Width.MEDIUM)
                                          .withValidation(Field::isRequired);

    /**
     * An optional field for that defines the queue size for the {@link #poll(long, TimeUnit) consumer}. Note that this
     * queue contains <em>lists</em> of events, and the size of the queue will affect how many <em>lists</em> can be in
     * the queue at once.
     */
    public static final Field MAX_QUEUE_SIZE = Field.create("max.queue.size")
                                                    .withDisplayName("Size of consumer event queues")
                                                    .withType(Type.INT)
                                                    .withWidth(Width.SHORT)
                                                    .withImportance(Importance.HIGH)
                                                    .withDescription("Maximum size of the queue that holds lists of change events. Defaults to 32 since this holds lists of events rather than individual events.")
                                                    .withDefault(32);

    /**
     * An optional field that specifies the name of the class that implements the {@link OffsetBackingStore} interface,
     * and that will be used to store offsets recorded by the connector.
     */
    public static final Field OFFSET_STORAGE = Field.create("offset.storage")
                                                    .withDescription("The Java class that implements the `OffsetBackingStore` "
                                                            + "interface, used to periodically store offsets so that, upon "
                                                            + "restart, the connector can resume where it last left off.")
                                                    .withDefault(FileOffsetBackingStore.class.getName());

    /**
     * An optional field that specifies the file location for the {@link FileOffsetBackingStore}.
     * 
     * @see #OFFSET_STORAGE
     */
    public static final Field OFFSET_STORAGE_FILE_FILENAME = Field.create(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG)
                                                                  .withDescription("The file where offsets are to be stored. Required when "
                                                                          + "'offset.storage' is set to the " +
                                                                          FileOffsetBackingStore.class.getName() + " class.")
                                                                  .withDefault("");

    /**
     * An optional field that specifies the file location for the {@link KafkaOffsetBackingStore}.
     * 
     * @see #OFFSET_STORAGE
     */
    public static final Field OFFSET_STORAGE_KAFKA_TOPIC = Field.create(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG)
                                                                .withDescription("The name of the Kafka topic where offsets are to be stored. "
                                                                        + "Required with other properties when 'offset.storage' is set to the "
                                                                        +
                                                                        KafkaOffsetBackingStore.class.getName() + " class.")
                                                                .withDefault("");

    /**
     * An optional advanced field that specifies the maximum amount of time that the embedded connector should wait
     * for an offset commit to complete.
     */
    public static final Field OFFSET_FLUSH_INTERVAL_MS = Field.create("offset.flush.interval.ms")
                                                              .withDescription("Interval at which to try committing offsets. The default is 1 minute.")
                                                              .withDefault(60000L)
                                                              .withValidation(Field::isNonNegativeInteger);

    /**
     * An optional advanced field that specifies the maximum amount of time that the embedded connector should wait
     * for an offset commit to complete.
     */
    public static final Field OFFSET_COMMIT_TIMEOUT_MS = Field.create("offset.flush.timeout.ms")
                                                              .withDescription("Maximum number of milliseconds to wait for records to flush and partition offset data to be"
                                                                      + " committed to offset storage before cancelling the process and restoring the offset "
                                                                      + "data to be committed in a future attempt.")
                                                              .withDefault(5000L)
                                                              .withValidation(Field::isPositiveInteger);

    protected static final Field INTERNAL_KEY_CONVERTER_CLASS = Field.create("internal.key.converter")
                                                                     .withDescription("The Converter class that should be used to serialize and deserialize key data for offsets.")
                                                                     .withDefault(JsonConverter.class.getName());

    protected static final Field INTERNAL_VALUE_CONVERTER_CLASS = Field.create("internal.value.converter")
                                                                       .withDescription("The Converter class that should be used to serialize and deserialize value data for offsets.")
                                                                       .withDefault(JsonConverter.class.getName());

    /**
     * The array of all exposed fields.
     */
    protected static final Field.Set ALL_FIELDS = Field.setOf(NAME, MAX_QUEUE_SIZE, OFFSET_STORAGE, OFFSET_STORAGE_FILE_FILENAME,
                                                              OFFSET_FLUSH_INTERVAL_MS, OFFSET_COMMIT_TIMEOUT_MS,
                                                              INTERNAL_KEY_CONVERTER_CLASS, INTERNAL_VALUE_CONVERTER_CLASS);

    /**
     * Callback function which informs users about the various stages a connector goes through during startup
     */
    public interface ConnectorCallback {

        /**
         * Called when a connector experiences a failure.
         * 
         * @param name the name of the connector; never null
         * @param message the error message
         * @param error the exception; may be null
         */
        default void connectorFailed(String name, String message, Throwable error) {
            // nothing by default
        }

        /**
         * Called after a connector has been successfully started by the engine; i.e. {@link SourceConnector#start(Map)} has
         * completed successfully
         * 
         * @param name the name of the connector; never null
         */
        default void connectorStarted(String name) {
            // nothing by default
        }

        /**
         * Called after a connector has been successfully stopped by the engine; i.e. {@link SourceConnector#stop()} has
         * completed successfully
         * 
         * @param name the name of the connector; never null
         */
        default void connectorStopped(String name) {
            // nothing by default
        }

        /**
         * Called after a connector task has been successfully started by the engine; i.e. {@link SourceTask#start(Map)} has
         * completed successfully
         * 
         * @param name the name of the connector; never null
         * @param taskNumber the 1-based task number that was started
         * @param totalTaskCount the total number of tasks configured
         */
        default void taskStarted(String name, int taskNumber, int totalTaskCount) {
            // nothing by default
        }

        /**
         * Called after a connector task has been successfully stopped by the engine; i.e. {@link SourceTask#stop()} has
         * completed successfully
         * 
         * @param name the name of the connector; never null
         * @param taskNumber the 1-based task number that was stopped
         * @param totalTaskCount the total number of tasks configured
         */
        default void taskStopped(String name, int taskNumber, int totalTaskCount) {
            // nothing by default
        }

    }

    private final Logger logger = LoggerFactory.getLogger(getClass());
    private final String name;
    private final Configuration config;
    private final Clock clock;
    private final ExecutorService executor;
    private final Runnable executorShutdown;
    private final AtomicBoolean shutdown = new AtomicBoolean(false);
    private final ConcurrentMap<String, DeployedConnector> workers = new ConcurrentHashMap<>();
    private final BlockingQueue<List<ChangeEvent>> eventQueue;
    private final int maxQueueSize;
    private final long commitTimeoutMs;
    private final ClassLoader classLoader;
    private final Converter keyConverter;
    private final Converter valueConverter;
    private final WorkerConfig workerConfig;
    private final AtomicBoolean running = new AtomicBoolean(false);
    private volatile OffsetBackingStore offsetStore;
    private volatile OffsetCommitPolicy offsetCommitPolicy;

    /**
     * Create a new engine that can run one or more connectors and allow a single consumer to {@link #poll(long, TimeUnit) consume
     * events}.
     * <p>
     * The classloader used to load this class will be used to load the {@link OffsetBackingStore} and {@link Converter}
     * implementations specified in the configuration, and as a default class loader used to load the {@link SourceConnector} and
     * {@link SourceTask} implementations when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying
     * connectors}. Note that a specific class loader can be specified when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying each connector}.
     * 
     * @param config the configuration; may not be null
     */
    public ConnectorEngine(Configuration config) {
        this(config, null, null, null);
    }

    /**
     * Create a new engine that can run one or more connectors and allow a single consumer to {@link #poll(long, TimeUnit) consume
     * events}.
     * <p>
     * When an {@link ExecutorService} is supplied, this engine uses it to run the tasks associated with the connectors but
     * will not {@link ExecutorService#shutdown() shut it down} when this engine is {@link #close() shutdown}. On the other
     * hand, if an {@link ExecutorService} is not supplied, this engine will instead create its own and will automatically shut it
     * down when this engine is {@link #close() shutdown}.
     * <p>
     * The classloader used to load this class will be used to load the {@link OffsetBackingStore} and {@link Converter}
     * implementations specified in the configuration, and as a default class loader used to load the {@link SourceConnector} and
     * {@link SourceTask} implementations when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying
     * connectors}. Note that a specific class loader can be specified when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying each connector}.
     * 
     * @param config the configuration; may not be null
     * @param executor the executor service with which the connector tasks should be run; may be null if a new
     *            {@link ExecutorService} should be used and shutdown when the engine is {@link #close() shutdown}
     */
    public ConnectorEngine(Configuration config, ExecutorService executor) {
        this(config, executor, null, null);
    }

    /**
     * Create a new engine that can run one or more connectors and allow a single consumer to {@link #poll(long, TimeUnit) consume
     * events}.
     * <p>
     * When an {@link ExecutorService} is supplied, this engine uses it to run the tasks associated with the connectors but
     * will not {@link ExecutorService#shutdown() shut it down} when this engine is {@link #close() shutdown}. On the other
     * hand, if an {@link ExecutorService} is not supplied, this engine will instead create its own and will automatically shut it
     * down when this engine is {@link #close() shutdown}.
     * <p>
     * The supplied class loader is used primarily to load the {@link OffsetBackingStore} and {@link Converter} implementations
     * specified in the configuration, and as a default class loader used to load the {@link SourceConnector} and
     * {@link SourceTask} implementations when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying
     * connectors}. Note that a specific class loader can be specified when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying each connector}.
     * 
     * @param config the configuration; may not be null
     * @param executor the executor service with which the connector tasks should be run; may be null if a new
     *            {@link ExecutorService} should be used and shutdown when the engine is {@link #stopAllConnectors(Runnable)
     *            stopped}
     * @param classLoader the class loader used to load the key and value converters;
     *            may be null if this engine's class loader should be used
     */
    public ConnectorEngine(Configuration config, ExecutorService executor, ClassLoader classLoader) {
        this(config, executor, classLoader, null);
    }

    /**
     * Create a new engine that can run one or more connectors and allow a single consumer to {@link #poll(long, TimeUnit) consume
     * events}.
     * <p>
     * When an {@link ExecutorService} is supplied, this engine uses it to run the tasks associated with the connectors but
     * will not {@link ExecutorService#shutdown() shut it down} when this engine is {@link #close() shutdown}. On the other
     * hand, if an {@link ExecutorService} is not supplied, this engine will instead create its own and will automatically shut it
     * down when this engine is {@link #close() shutdown}.
     * <p>
     * The supplied class loader is used primarily to load the {@link OffsetBackingStore} and {@link Converter} implementations
     * specified in the configuration, and as a default class loader used to load the {@link SourceConnector} and
     * {@link SourceTask} implementations when {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying
     * connectors}. Note that a specific class loader can be specified when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying each connector}.
     * 
     * @param config the configuration; may not be null
     * @param executor the executor service with which the connector tasks should be run; may be null if a new
     *            {@link ExecutorService} should be used and shutdown when the engine is {@link #close() shutdown}
     * @param classLoader the class loader used to load the key and value converters;
     *            may be null if this engine's class loader should be used
     * @param clock the clock used to determine the current time; may be null if the {@link Clock#system() system clock} should be
     *            used
     */
    public ConnectorEngine(Configuration config, ExecutorService executor, ClassLoader classLoader, Clock clock) {
        config.validateAndThrow(ALL_FIELDS, "ConnectorEngine configuration is invalid");
        this.config = config;
        this.clock = clock != null ? clock : Clock.system();
        this.classLoader = classLoader != null ? classLoader : getClass().getClassLoader();
        this.maxQueueSize = this.config.getInteger(MAX_QUEUE_SIZE);
        this.name = this.config.getString(NAME);
        this.commitTimeoutMs = this.config.getLong(OFFSET_COMMIT_TIMEOUT_MS);
        this.eventQueue = new LinkedBlockingQueue<>(maxQueueSize);
        if (executor != null) {
            this.executor = executor;
            this.executorShutdown = () -> {};
        } else {
            ThreadFactory factory = Threads.createFactory(name() + "-task-threads", name() + "-task");
            this.executor = Executors.newCachedThreadPool(factory);
            this.executorShutdown = this.executor::shutdown;
        }
        // Set up the converters that the offset storage will use ...
        keyConverter = config.getInstance(INTERNAL_KEY_CONVERTER_CLASS, Converter.class, () -> this.classLoader);
        keyConverter.configure(config.subset(INTERNAL_KEY_CONVERTER_CLASS.name() + ".", true).asMap(), true);
        valueConverter = config.getInstance(INTERNAL_VALUE_CONVERTER_CLASS, Converter.class, () -> this.classLoader);
        Configuration valueConverterConfig = config;
        if (valueConverter instanceof JsonConverter) {
            // Make sure that the JSON converter is configured to NOT enable schemas ...
            valueConverterConfig = config.edit().with(INTERNAL_VALUE_CONVERTER_CLASS + ".schemas.enable", false).build();
        }
        valueConverter.configure(valueConverterConfig.subset(INTERNAL_VALUE_CONVERTER_CLASS.name() + ".", true).asMap(), false);

        // Create the worker config, adding extra fields that are required for validation of a worker config
        // but that are not used within the embedded engine (since the source records are never serialized) ...
        Map<String, String> embeddedConfig = config.asMap(ALL_FIELDS);
        embeddedConfig.put(WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, JsonConverter.class.getName());
        embeddedConfig.put(WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, JsonConverter.class.getName());
        workerConfig = new EmbeddedWorkerConfig(embeddedConfig);

        // Create the offset store implementation ...
        offsetStore = config.getInstance(OFFSET_STORAGE, OffsetBackingStore.class, () -> this.classLoader);
        logger.debug("Create connector engine '{}' with configuration: {}", name, config.withMaskedPasswords());
    }

    /**
     * Get the name of this engine.
     * 
     * @return the engine name; never null
     */
    protected String name() {
        return this.config.getString(NAME);
    }

    /**
     * Start this engine's resources and any deployed connectors. Once started, any additional connectors will be started
     * immediately when they are {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deployed}.
     * 
     * @see #stopAllConnectors(Runnable)
     * @see #close()
     */
    public synchronized void start() {
        checkStatus();
        if (running.compareAndSet(false, true)) {
            logger.debug("Starting connector engine '{}'", name, offsetStore);
            try {
                // Instantiate and initialize the offset store ...
                offsetStore = config.getInstance(OFFSET_STORAGE, OffsetBackingStore.class, () -> this.classLoader);
                offsetStore.configure(workerConfig);
                offsetStore.start();

                // Set up the offset commit policy ...
                long offsetPeriodMs = config.getLong(OFFSET_FLUSH_INTERVAL_MS);
                offsetCommitPolicy = OffsetCommitPolicy.periodic(offsetPeriodMs, TimeUnit.MILLISECONDS);

                // Start any existing connector workers ...
                workers.forEach((connectorName, worker) -> {
                    logger.debug("Starting connector '{}' in engine '{}'", connectorName, name());
                    worker.start();
                });
            } catch (Throwable t) {
                running.set(false);
            }
        }
    }

    /**
     * Wrap the supplied offset storage reader with a delegate implementation that also logs the partitions and offsets that are
     * read.
     * 
     * @param reader the actual offset reader; may not be null
     * @param logger the logger to which trace messages should be written; may not be null
     * @return the instrumented reader implementation; never null
     */
    protected static OffsetStorageReader instrument(OffsetStorageReader reader, Logger logger) {
        return new OffsetStorageReader() {
            @Override
            public <T> Map<Map<String, T>, Map<String, Object>> offsets(Collection<Map<String, T>> partitions) {
                logger.trace("Reading offsets for {} partitions", partitions.size());
                Map<Map<String, T>, Map<String, Object>> results = reader.offsets(partitions);
                if (logger.isTraceEnabled()) {
                    logger.trace("Read offsets for {} partitions:", partitions.size());
                    AtomicInteger partitionNumber = new AtomicInteger();
                    results.forEach((partition, offset) -> {
                        logger.trace("Offset for partition {} {}: {}", partitionNumber.incrementAndGet(), partition, offset);
                    });
                }
                return results;
            }

            @Override
            public <T> Map<String, Object> offset(Map<String, T> partition) {
                Map<String, Object> offset = reader.offset(partition);
                logger.trace("Offset for partition {}: {}", partition, offset);
                return offset;
            }
        };
    }

    /**
     * Determine if this engine has been {@link #start() started} and is still running.
     * 
     * @return {@code true} if this engine is currently running, or {@code false} otherwise
     */
    public boolean isRunning() {
        return running.get();
    }

    @Override
    public List<ChangeEvent> poll() throws InterruptedException {
        if (shutdown.get()) {
            return pollResultsWhenShutdown();
        }
        return withEvents(eventQueue.remove());
    }

    @Override
    public List<ChangeEvent> poll(long timeout, TimeUnit unit) throws InterruptedException {
        if (shutdown.get()) {
            return pollResultsWhenShutdown();
        }
        return withEvents(eventQueue.poll(timeout, unit));
    }

    protected List<ChangeEvent> pollResultsWhenShutdown() {
        logger.trace("Engine '{}' is closed so returning no events", name);
        return Collections.emptyList();
    }

    protected List<ChangeEvent> withEvents(List<ChangeEvent> events) {
        if (events == null) events = Collections.emptyList();
        if (logger.isTraceEnabled()) {
            logger.trace("Returning {} events for engine '{}'", events.size(), name);
        }
        return events;
    }

    /**
     * Add a connector with the given configuration, replacing any configuration for a connector previously deployed
     * with the same name. If this engine is already {@link #start() started}, then any existing connector will be stopped
     * and the new connector will be started as part of this deployment operation.
     * <p>
     * This method uses the engine's class loader to load the {@link SourceConnector} and {@link SourceTask} implementations when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying connectors}.
     * 
     * @param config the configuration for the connector; may not be null
     * @return {@code true} if the connector was started, or {@code false} if the engine was not running
     * @throws ClassNotFoundException if the connector or task classes could not be found
     * @throws InstantiationException if the connector or task classes could not be instantiated
     * @throws IllegalAccessException if the connector or task classes could not be accessed or used
     * @throws InvalidConfigurationException if the connector configuration is not valid
     * @throws InterruptedException if this thread was blocked waiting for the existing connector to stop completely
     * 
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #startConnector(String)
     * @see #stopConnector(String, Runnable)
     * @see #removeConnector(String, Runnable)
     */
    public synchronized boolean addConnector(Configuration config)
            throws ClassNotFoundException, InstantiationException, IllegalAccessException, InterruptedException {
        return addConnector(config, null, null);
    }

    /**
     * Add a connector with the given configuration, replacing any configuration for a connector previously deployed
     * with the same name. If this engine is already {@link #start() started}, then any existing connector will be stopped
     * and the new connector will be started as part of this deployment operation.
     * <p>
     * This method uses the engine's class loader to load the {@link SourceConnector} and {@link SourceTask} implementations when
     * {@link #addConnector(Configuration, ConnectorCallback, ClassLoader) deploying connectors}.
     * 
     * @param config the configuration for the connector; may not be null
     * @param callback the callback that should be used to report lifecycle state changes of the new connector; may be null
     * @return {@code true} if the connector was started, or {@code false} if the engine was not running
     * @throws ClassNotFoundException if the connector or task classes could not be found
     * @throws InstantiationException if the connector or task classes could not be instantiated
     * @throws IllegalAccessException if the connector or task classes could not be accessed or used
     * @throws InvalidConfigurationException if the connector configuration is not valid
     * @throws InterruptedException if this thread was blocked waiting for the existing connector to stop completely
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #startConnector(String)
     * @see #stopConnector(String, Runnable)
     * @see #removeConnector(String, Runnable)
     */
    public synchronized boolean addConnector(Configuration config, ConnectorCallback callback)
            throws ClassNotFoundException, InstantiationException, IllegalAccessException, InterruptedException {
        return addConnector(config, callback, null);
    }

    /**
     * Add a connector with the given configuration, replacing any configuration for a connector previously deployed
     * with the same name. If this engine is already {@link #start() started}, then any existing connector will be stopped
     * and the new connector will be started as part of this deployment operation.
     * 
     * @param config the configuration for the connector; may not be null
     * @param callback the callback that should be used to report lifecycle state changes of the new connector; may be null
     * @param classLoader an optional class loader that should be used to load all classes associated with the connector;
     *            may be null if this engine's class loader should be used
     * @return {@code true} if the connector was started, or {@code false} if the engine was not running
     * @throws ClassNotFoundException if the connector or task classes could not be found
     * @throws InstantiationException if the connector or task classes could not be instantiated
     * @throws IllegalAccessException if the connector or task classes could not be accessed or used
     * @throws InvalidConfigurationException if the connector configuration is not valid
     * @throws InterruptedException if this thread was blocked waiting for the existing connector to stop completely
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #startConnector(String)
     * @see #stopConnector(String, Runnable)
     * @see #removeConnector(String, Runnable)
     */
    public synchronized boolean addConnector(Configuration config, ConnectorCallback callback, ClassLoader classLoader)
            throws ClassNotFoundException, InstantiationException, IllegalAccessException, InterruptedException {
        checkStatus();
        if (classLoader == null) classLoader = this.classLoader;

        // Create a new worker that will run this connector ...
        DeployedConnector worker = new DeployedConnector(config, this.executor, classLoader, callback, null);
        logger.debug("Adding connector '{}' to engine '{}' with config: {}", worker.connectorName(), name, config.withMaskedPasswords());

        // Handle any existing configurations ...
        DeployedConnector existing = workers.get(worker.connectorName());
        if (existing != null) {
            if (running.get()) {
                try {
                    // Stop the existing connector first and wait for it to stop...
                    logger.trace("Stopping existing connector '{}' in engine '{}' before deploying new config", worker.connectorName(),
                                 name);
                    existing.stop(null).get();
                    logger.trace("Stopped existing connector '{}' in engine '{}' before deploying new config", worker.connectorName(),
                                 name);
                } catch (ExecutionException e) {
                    throw new RuntimeException(e);
                }
                // Remove the worker ...
                workers.remove(existing.connectorName());
            } else {
                // Make sure that the existing worker is not running, either
                assert !existing.isRunning();
            }
        }

        // Record the configuration ...
        logger.trace("Saving configuration for connector '{}' in engine '{}':", worker.connectorName(), name,
                     worker.config.withMaskedPasswords());
        workers.put(worker.connectorName(), worker);
        if (running.get()) {
            // Start the connector ...
            return worker.start();
        }
        return false;
    }

    /**
     * Get the names of all of the connectors that have been added, regardless of whether any of them is running.
     * 
     * @return the unmodifiable set of connector names; never null but possibly empty
     */
    public synchronized Set<String> allConnectorNames() {
        return Collections.unmodifiableSet(workers.keySet());
    }

    /**
     * Get the names of all of the currently-running connectors.
     * 
     * @return the unmodifiable set of connector names; never null but possibly empty
     */
    public synchronized Set<String> runningConnectorNames() {
        if (!isRunning()) return Collections.emptySet();
        Set<String> names = new HashSet<>();
        workers.forEach((connectorName, worker) -> {
            if (worker.isRunning()) names.add(connectorName);
        });
        return Collections.unmodifiableSet(names);
    }

    /**
     * Start an already deployed connector with the given name.
     * 
     * @param connectorName the name of the deployed connector to be started; may not be null
     * @return {@code true} if the connector was started, or {@code false} if there was no connector with the given name
     *         or this engine is not running
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #stopConnector(String, Runnable)
     * @see #removeConnector(String, Runnable)
     */
    public synchronized boolean startConnector(String connectorName) {
        checkStatus();
        logger.debug("Starting connector '{}' in engine '{}'", connectorName, name);
        DeployedConnector existing = workers.get(connectorName);
        if (existing != null && running.get()) {
            return existing.start();
        }
        return false;
    }

    /**
     * Stop the connector with the given name, but do not remove the configuration.
     * 
     * @param connectorName the name of the deployed connector
     * @return a future that can be called to wait for the connector to complete their shutdown; never null but empty
     *         if no connector exists with the given name
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #startConnector(String)
     * @see #removeConnector(String, Runnable)
     */
    public Optional<Future<Void>> stopConnector(String connectorName) {
        return stopConnector(connectorName, null);
    }

    /**
     * Stop the connector with the given name, but do not remove the configuration.
     * 
     * @param connectorName the name of the deployed connector
     * @param uponCompletion optional function that is called the connector has stopped; may be null if not needed
     * @return a future that can be called to wait for the connector to complete their shutdown; never null but empty
     *         if no connector exists with the given name
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #startConnector(String)
     * @see #removeConnector(String, Runnable)
     */
    public synchronized Optional<Future<Void>> stopConnector(String connectorName, Runnable uponCompletion) {
        checkStatus();
        logger.debug("Stopping connector '{}' in engine '{}'", connectorName, name);
        DeployedConnector worker = workers.get(connectorName);
        if (worker != null) {
            if (uponCompletion == null) uponCompletion = () -> {};
            return Optional.of(worker.stop(uponCompletion));
        }
        return Optional.empty();
    }

    /**
     * Stop all connectors and remove their configurations.
     * 
     * @return a future that can be called to wait for all connectors to complete their shutdown
     */
    public synchronized Future<Void> stopAllConnectors() {
        return stopAllConnectors(null);
    }

    /**
     * Stop all connectors and remove their configurations, optionally calling the supplied function when this operation
     * completes.
     * 
     * @param uponCompletion optional function that is called when all connectors have stopped; may be null if not needed
     * @return a future that can be called to wait for all connectors to complete their shutdown
     */
    public synchronized Future<Void> stopAllConnectors(Runnable uponCompletion) {
        List<CompletableFuture<Void>> stopFutures = new ArrayList<>();
        if (!workers.isEmpty()) {
            // Stop all of the connectors ...
            logger.trace("Stopping all connectors in engine '{}'", name);
            workers.values().forEach(worker -> {
                stopFutures.add(worker.stop(() -> {}));
            });
        }

        // Return a future that is done when all connector shutdown futures are done ...
        if (uponCompletion == null) uponCompletion = () -> {};
        return futureWithAllOf(stopFutures).thenRun(uponCompletion);
    }

    /**
     * Stop the connector with the given name and remove its configuration from this engine.
     * 
     * @param connectorName the name of the deployed connector
     * @return a future that can be called to wait for the connector to complete their shutdown; never null but empty
     *         if no connector exists with the given name
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #stopAllConnectors()
     * @see #stopAllConnectors(Runnable)
     * @see #removeConnector(String, Runnable)
     * @see #removeAllConnectors()
     * @see #removeAllConnectors(Runnable)
     */
    public Optional<Future<Void>> removeConnector(String connectorName) {
        return removeConnector(connectorName, null);
    }

    /**
     * Stop the connector with the given name and remove its configuration from this engine. The connector is stopped
     * asynchronously, so this method returns a future that can be used to track when this asynchronous work is completed.
     * 
     * @param connectorName the name of the deployed connector
     * @param uponCompletion optional function that is always called when the existing connector has been stopped and removed; may
     *            be null if not needed
     * @return an optional with a future that will complete when the existing connector has been stopped and removed, or
     *         that will be empty if there is no connector with the given name
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #stopAllConnectors()
     * @see #stopAllConnectors(Runnable)
     * @see #removeConnector(String)
     * @see #removeAllConnectors()
     * @see #removeAllConnectors(Runnable)
     */
    public synchronized Optional<Future<Void>> removeConnector(String connectorName, Runnable uponCompletion) {
        checkStatus();
        DeployedConnector worker = workers.remove(connectorName);
        if (worker != null) {
            if (uponCompletion == null) uponCompletion = () -> {};
            logger.debug("Stopping and removing connector '{}' in engine '{}'", connectorName, name);
            return Optional.of(worker.stop(uponCompletion));
        }
        logger.debug("Removing connector '{}' in engine '{}'", connectorName, name);
        return Optional.empty();
    }

    /**
     * Stop all connectors and remove their configuration from this engine.
     * 
     * @return a future that will complete when all existing connectors have been stopped and removed, even when there
     *         are no existing connectors
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #stopConnector(String, Runnable)
     * @see #stopAllConnectors()
     * @see #stopAllConnectors(Runnable)
     * @see #removeConnector(String)
     * @see #removeConnector(String, Runnable)
     * @see #removeAllConnectors(Runnable)
     */
    public Future<Void> removeAllConnectors() {
        return removeAllConnectors(null);
    }

    /**
     * Stop all connectors and remove their configuration from this engine.
     * 
     * @param uponCompletion function that will be called either after all connectors have been stopped and removed, or
     *            immediately if there are no existing connectors; may be null if not needed
     * @return a future that will complete when all existing connectors have been stopped and removed, even when there
     *         are no existing connectors
     * 
     * @see #addConnector(Configuration)
     * @see #addConnector(Configuration, ConnectorCallback)
     * @see #addConnector(Configuration, ConnectorCallback, ClassLoader)
     * @see #stopConnector(String, Runnable)
     * @see #stopAllConnectors()
     * @see #stopAllConnectors(Runnable)
     * @see #removeConnector(String)
     * @see #removeConnector(String, Runnable)
     * @see #removeAllConnectors()
     */
    public synchronized Future<Void> removeAllConnectors(Runnable uponCompletion) {
        checkStatus();
        if (uponCompletion == null) uponCompletion = () -> {};
        logger.debug("Removing all connectors in engine '{}'", name);
        if (workers.isEmpty()) {
            return CompletableFuture.completedFuture(null).thenRun(uponCompletion);
        }
        // Stop each of the workers ...
        List<CompletableFuture<Void>> stopFutures = new ArrayList<>();
        workers.values().forEach(worker -> {
            stopFutures.add(worker.stop(null));
        });
        workers.clear();
        return futureWithAllOf(stopFutures).thenRun(uponCompletion);
    }

    protected void checkStatus() {
        if (shutdown.get()) throw new IllegalStateException("The engine has already been closed and cannot be used");
    }

    @Override
    public boolean isClosed() {
        return shutdown.get();
    }

    /**
     * Stop all connectors, remove their configurations, block until all connector tasks have been stopped, and then
     * clean up all resources owned by this engine. Once this method is called, the engine can no longer be used.
     * 
     * @throws InterruptedException if the calling thread is interrupted while waiting for the connector tasks to stop
     * @throws ExecutionException if another exception was thrown while waiting for the connector tasks to stop
     */
    @Override
    public synchronized void close() throws InterruptedException, ExecutionException {
        if (!isClosed()) {
            logger.trace("Closing connector engine '{}'", name);
            stopAllConnectors(() -> {}).get();
            // Shutdown the executor if needed ...
            executorShutdown.run();
            shutdown.set(true);
            running.set(false);
            logger.debug("Closed connector engine '{}'", name);
        }
    }

    private static CompletableFuture<Void> futureWithAllOf(List<CompletableFuture<Void>> futures) {
        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[futures.size()]));
    }

    /**
     * Used to hold onto a {@link DeployedConnector}'s running tasks and state, with logic to ensure that all tasks
     * are properly stopped exactly one time.
     */
    @ThreadSafe
    protected final class ConnectorTasks {
        private final AtomicBoolean allRunning = new AtomicBoolean(true);
        private final List<ConnectorTask> startedTasks = new ArrayList<>();
        private final List<ConnectorTask> runningTasks = new ArrayList<>();
        private final List<CompletableFuture<Void>> taskFutures = new ArrayList<>();
        private volatile CompletableFuture<Void> master;

        public ConnectorTasks() {
        }

        /**
         * Determine if the tasks are still running.
         * 
         * @return {@code true} if the tasks are still running or runnable, or {@code false} if any or all of the tasks
         *         have been stopped for any reason, including errors
         */
        public boolean stillRunning() {
            return allRunning.get();
        }

        /**
         * Add a connector task that has already been started and is ready to be {@link #runEachTask(Executor, Function) run}.
         * 
         * @param task the connector task; may not be null
         */
        public synchronized void addStartedTask(ConnectorTask task) {
            if (task != null) {
                startedTasks.add(task);
                runningTasks.remove(task);
            }
        }

        /**
         * Submit to the supplied executor operations to continuously poll the tasks previously
         * {@link #addStartedTask(ConnectorTask) started}.
         * 
         * @param executor the executor; never null
         * @param function the function that returns the runnable for each task; may not be null and may never return null
         */
        public synchronized void runEachTask(Executor executor, Function<ConnectorTask, Runnable> function) {
            startedTasks.forEach(task -> {
                Runnable runnable = function.apply(task);
                CompletableFuture<Void> future = CompletableFuture.runAsync(runnable, executor);
                taskFutures.add(future);
                runningTasks.add(task);
            });
            startedTasks.clear();
        }

        /**
         * Called to signal that all running tasks should be stopped.
         * 
         * @return the future representing the completion of all tasks; never null
         */
        public synchronized CompletableFuture<Void> stopTasks() {
            if (allRunning.compareAndSet(true, false)) {
                // Go through all of the connectors and stop them ...
                startedTasks.forEach(ConnectorTask::stop);
                runningTasks.forEach(ConnectorTask::stop);
            }
            return master;
        }

        /**
         * Define the function that should be performed when all tasks have completed. This should be called after
         * {@link #runEachTask(Executor, Function)} is called for all of the tasks.
         * 
         * @param runnable the function; may not be null
         */
        public synchronized void uponCompletionOfAllTasks(Runnable runnable) {
            master = futureWithAllOf(taskFutures).thenRun(() -> {
                startedTasks.clear();
                runningTasks.clear();
                taskFutures.clear();
                runnable.run();
            });
        }
    }

    /**
     * A simple wrapper around a {@link SourceTask} with some state specific to that task.
     */
    @Immutable
    protected final class ConnectorTask {
        private final String connectorName;
        private final SourceTask task;
        private final int taskNum;
        private final int totalTaskCount;
        private final AtomicBoolean running = new AtomicBoolean(true);
        private final Runnable uponStop;
        private volatile long recordsSinceLastCommit = 0L;
        private volatile long timeSinceLastCommitMillis = 0L;
        private final OffsetStorageWriter offsetWriter;
        private final OffsetCommitPolicy offsetCommitPolicy;

        public ConnectorTask(String connectorName, SourceTask task, int taskNum, int totalTaskCount, OffsetStorageWriter offsetWriter,
                             OffsetCommitPolicy offsetCommitPolicy,
                             Runnable uponStop) {
            this.connectorName = connectorName;
            this.task = task;
            this.taskNum = taskNum;
            this.totalTaskCount = totalTaskCount;
            this.uponStop = uponStop;
            this.offsetCommitPolicy = offsetCommitPolicy;
            this.offsetWriter = offsetWriter;
        }

        public SourceTask task() {
            return task;
        }

        public int taskNum() {
            return taskNum;
        }

        public boolean stop() {
            if (running.compareAndSet(true, false)) {
                try {
                    // First stop the task ...
                    try {
                        logger.trace("Stopping task {} of {} for connector '{}' in engine '{}'",
                                     taskNum, totalTaskCount, connectorName, name());
                        task.stop();
                        logger.trace("Stopped task {} of {} for connector '{}' in engine '{}'",
                                     taskNum, totalTaskCount, connectorName, name());
                    } finally {
                        // And always flush offsets
                        flushOffsets();
                    }
                } finally {
                    uponStop.run();
                }
                return true;
            }
            return false;
        }

        protected void commitOffset(SourceRecord record, String connectorName, long taskSequenceNumber,
                                    AtomicLong maxSequenceCommitted) {
            // Check if we've already committed a record past this record ...
            try {
                logger.trace("Committing record for connector '{}' task {} in engine {}", connectorName, taskNum, name);
                task.commitRecord(record);
            } catch (InterruptedException e) {
                // This is called by the consumer, so if it's been interrupted just return
                Thread.interrupted();
                return;
            }
            if (maxSequenceCommitted.get() <= taskSequenceNumber) {
                // We've not yet committed a record this far ...
                logger.trace("Recording offset for connector '{}' task {} in engine {}: {}", connectorName, taskNum, name,
                             record.sourceOffset());
                offsetWriter.offset(record.sourcePartition(), record.sourceOffset());
                maxSequenceCommitted.set(taskSequenceNumber);
            }
            maybeFlushOffsets();
        }

        protected void maybeFlushOffsets() {
            // Determine if we need to commit to offset storage ...
            if (offsetCommitPolicy.performCommit(recordsSinceLastCommit, timeSinceLastCommitMillis, TimeUnit.MILLISECONDS)) {
                flushOffsets();
            }
        }

        /**
         * Flush offsets to storage.
         */
        protected void flushOffsets() {
            logger.trace("Flushing offsets for task {} of {} for connector '{}' in engine '{}'",
                         taskNum, totalTaskCount, connectorName, name());
            long started = clock.currentTimeInMillis();
            long timeout = started + commitTimeoutMs;
            if (!offsetWriter.beginFlush()) return;
            Future<Void> flush = offsetWriter.doFlush(this::completedFlush);
            if (flush == null) return; // no offsets to commit ...

            // Wait until the offsets are flushed ...
            try {
                flush.get(Math.max(timeout - clock.currentTimeInMillis(), 0), TimeUnit.MILLISECONDS);
                // if we've gotten this far, the offsets have been committed so notify the task
                recordsSinceLastCommit = 0;
                timeSinceLastCommitMillis = clock.currentTimeInMillis();
            } catch (InterruptedException e) {
                logger.warn("Flush of {} offsets interrupted for task {} of {} for connector '{}' in engine '{}', cancelling", this,
                            taskNum, totalTaskCount, connectorName, name());
                offsetWriter.cancelFlush();
            } catch (ExecutionException e) {
                logger.error("Flush of {} offsets for task {} of {} for connector '{}' in engine '{}' threw an unexpected exception: ",
                             this, taskNum, totalTaskCount, connectorName, name(), e);
                offsetWriter.cancelFlush();
            } catch (TimeoutException e) {
                logger.error("Timed out waiting to flush {} offsets to storage for task {} of {} for connector '{}' in engine '{}'", this,
                             taskNum, totalTaskCount, connectorName, name());
                offsetWriter.cancelFlush();
            }
        }

        protected void completedFlush(Throwable error, Void result) {
            if (error != null) {
                logger.error("Failed to flush {} offsets to storage for task {} of {} for connector '{}' in engine '{}': ", this, taskNum,
                             totalTaskCount, connectorName, name(), error);
            } else {
                logger.trace("Finished flushing {} offsets to storage for task {} of {} for connector '{}' in engine '{}'", this, taskNum,
                             totalTaskCount, connectorName, name());
            }
        }

    }

    /**
     * A deployed connector that has the connector's name, configuration, classloader used to load the connector-related
     * classes, callback for all state transitions when the connector is run, and the {@link ConnectorTasks} object that
     * holds the running connector's tasks.
     */
    @ThreadSafe
    protected final class DeployedConnector {
        private final String connectorName;
        private final Configuration config;
        private final ClassLoader classLoader;
        private final ConnectorCallback callback;
        private final AtomicReference<ConnectorTasks> tasks = new AtomicReference<>();
        private final Runnable uponStop;

        public DeployedConnector(Configuration config, Executor executor, ClassLoader classLoader,
                                 ConnectorCallback callback, Runnable uponStop) throws InvalidConfigurationException {
            // Validate the configuration ...
            config.validateAndThrow(CONNECTOR_FIELDS);
            this.config = config;
            this.connectorName = this.config.getString(CONNECTOR_NAME);
            this.classLoader = classLoader;
            this.callback = callback != null ? callback : new ConnectorCallback() {
            };
            this.uponStop = uponStop != null ? uponStop : () -> {};
        }

        /**
         * Get the name of this connector.
         * 
         * @return the connector name; never null
         */
        public String connectorName() {
            return connectorName;
        }

        /**
         * Determine if this connector is already running or in the process or starting.
         * 
         * @return {@code true} if the connector is in the process of starting or has already been started
         */
        public boolean isRunning() {
            return tasks.get() != null;
        }

        /**
         * Attempt to start the connector's tasks if they are not already running.
         *
         * @return {@code true} if the connector was already running or was successfully started, or {@code false} if
         *         the connector could not be started due to a failure (reported to the callback)
         */
        public synchronized boolean start() {
            if (tasks.get() != null) return true;

            // We need to start the connector and its tasks ...
            final String connectorClassName = config.getString(CONNECTOR_CLASS);
            final int maxTasks = config.getInteger(CONNECTOR_TASKS_MAX);

            // Instantiate the connector ...
            SourceConnector newConnector = null;
            try {
                logger.trace("Instantiating connector instance '{}' in engine '{}'", connectorName, name());
                @SuppressWarnings("unchecked")
                Class<? extends SourceConnector> connectorClass = (Class<SourceConnector>) classLoader.loadClass(connectorClassName);
                newConnector = connectorClass.newInstance();
            } catch (ClassNotFoundException | InstantiationException | IllegalAccessException e) {
                callback.connectorFailed(connectorName,
                                         "Error while trying to instantiate connector " + connectorName + ": " + e.getMessage(), e);
                return false;
            }
            final SourceConnector connector = newConnector;

            // Initialize the connector using a context that does NOT respond to requests to reconfigure tasks ...
            try {
                logger.trace("Initializing connector instance '{}' in engine '{}'", connectorName, name());
                ConnectorContext context = workerConnectorContext(connectorName, callback);
                connector.initialize(context);
            } catch (Throwable e) {
                callback.connectorFailed(connectorName,
                                         "Error while trying to initialize connector " + connectorName + ": " + e.getMessage(), e);
                return false;
            }

            // Start the connector with the given properties and get the task configurations ...
            try {
                logger.trace("Starting connector instance '{}' in engine '{}'", connectorName, name());
                connector.start(config.asMap());
                callback.connectorStarted(connectorName);
            } catch (Throwable e) {
                callback.connectorFailed(connectorName,
                                         "Error while trying to start connector " + connectorName + ": " + e.getMessage(), e);
                return false;
            }

            // Get the configuration for each task ...
            Class<? extends Task> taskClass = connector.taskClass();
            List<Map<String, String>> taskConfigs = connector.taskConfigs(maxTasks);
            int taskCount = taskConfigs.size();

            // Now, start and run each task with the executor and get the future/stage for it ...
            ConnectorTasks tasks = new ConnectorTasks();
            AtomicInteger counter = new AtomicInteger(0);
            taskConfigs.forEach(taskConfig -> {
                int taskNumber = counter.incrementAndGet();
                ConnectorTask task = startTask(taskNumber, taskCount, tasks, taskConfig, taskClass);
                tasks.addStartedTask(task);
            });

            if (!tasks.stillRunning()) {
                // Something when wrong and we were not able to start all of the tasks for the connector,
                // but the problem was already logged and sent to the callback, so just return immediately
                tasks.stopTasks();
                return false;
            }

            // And begin polling the tasks ...
            tasks.runEachTask(executor, task -> createTaskRunner(task, taskCount, tasks));

            // All tasks were started, so define what will happen when they all stop ...
            tasks.uponCompletionOfAllTasks(() -> {
                logger.trace("All tasks for connector '{}' in engine '{}' have stopped, so requesting connector stop", connectorName,
                             name());
                try {
                    connector.stop();
                } finally {
                    try {
                        logger.debug("Stopped connector '{}' in engine '{}' after all tasks stopped and offsets flushed", connectorName,
                                     name());
                        callback.connectorStopped(connectorName);
                        this.tasks.set(null);
                    } finally {
                        uponStop.run();
                    }
                }
            });

            // The connector and its tasks were successfully started ...
            logger.trace("Started {} task(s) for connector '{}' in engine '{}'", taskCount, connectorName, name());
            this.tasks.set(tasks);
            return true;
        }

        /**
         * Start a task with the given details.
         * 
         * @param taskNum the 1-based number for the task; must be positive and less than or equal to {@code totalTaskCount}
         * @param totalTaskCount the total number of tasks that were configured; must be positive and greater than or equal
         *            to {@code taskNum}
         * @param tasks the collection of the tasks; may not be null
         * @param taskConfig the task configuration; may not be null
         * @param taskClass the class for the task; may not be null
         * @return the started task, or null if there was a problem and the task could not be started properly
         */
        protected ConnectorTask startTask(int taskNum, int totalTaskCount, ConnectorTasks tasks, Map<String, String> taskConfig,
                                          Class<? extends Task> taskClass) {
            if (!tasks.stillRunning()) {
                logger.trace("Skipping task {} for connector '{}' in engine '{}'", taskNum, connectorName, name());
                return null;
            }
            // Create the task ...
            logger.trace("Instantiating task {} for connector '{}' in engine '{}'", taskNum, connectorName, name());
            SourceTask task = null;
            try {
                task = (SourceTask) taskClass.newInstance();
            } catch (IllegalAccessException | InstantiationException t) {
                tasks.stopTasks();
                String msg = "Unable to instantiate connector's task class '" + taskClass.getName() + "': " + t.getMessage();
                logger.debug(msg, t);
                try {
                    callback.connectorFailed(connectorName, msg, t);
                } catch (Throwable c) {
                    logger.error("Error calling method on callback for connector '{}': {}", connectorName, c.getMessage(), c);
                }
                return null;
            }

            OffsetStorageWriter offsetWriter = new OffsetStorageWriter(offsetStore, name, keyConverter, valueConverter);
            OffsetStorageReader offsetReader = new OffsetStorageReaderImpl(offsetStore, name, keyConverter, valueConverter);
            OffsetStorageReader instrumentedOffsetReader = instrument(offsetReader, logger);

            // Initialize the task ...
            logger.trace("Initializing task {} for connector '{}' in engine '{}'", taskNum, connectorName, name());
            SourceTaskContext taskContext = () -> instrumentedOffsetReader;
            try {
                task.initialize(taskContext);
            } catch (Throwable t) {
                Configuration cfg = Configuration.from(taskConfig).withMaskedPasswords();
                String msg = "Unable to initialize task " + taskNum + " of " + totalTaskCount + " for connector '" + connectorName
                        + "' with config: " + cfg;
                tasks.stopTasks();
                logger.debug(msg, t);
                try {
                    callback.connectorFailed(connectorName, msg, t);
                } catch (Throwable c) {
                    logger.error("Error calling method on callback for connector '{}': {}", connectorName, c.getMessage(), c);
                }
                return null;
            }

            // Start the task ...
            logger.trace("Starting task {} of {} for connector '{}' in engine '{}'", taskNum, totalTaskCount, connectorName, name());
            try {
                task.start(taskConfig);
            } catch (Throwable t) {
                Configuration cfg = Configuration.from(taskConfig).withMaskedPasswords();
                String msg = "Connector '" + connectorName + "' will be stopped because task " + taskNum + " of " + totalTaskCount
                        + " failed during start, with connector config: " + cfg;
                tasks.stopTasks();
                logger.debug(msg, t);
                try {
                    callback.connectorFailed(connectorName, msg, t);
                } catch (Throwable c) {
                    logger.error("Error calling method on callback for connector '{}': {}", connectorName, c.getMessage(), c);
                }
                return null;
            }

            logger.trace("Started task {} of {} for connector '{}' in engine '{}'", taskNum, totalTaskCount, connectorName, name());
            try {
                callback.taskStarted(connectorName, taskNum, totalTaskCount);
            } catch (Throwable c) {
                logger.error("Error calling method on callback for connector '{}': {}", connectorName, c.getMessage(), c);
            }

            // Define the function that will be called when the task is stopped ...
            Runnable stopFunction = () -> {
                try {
                    callback.taskStopped(connectorName, taskNum, totalTaskCount);
                } catch (Throwable c) {
                    logger.error("Error calling method on callback for connector '{}': {}", connectorName, c.getMessage(), c);
                }
            };

            // Create the holder of all this information ...
            return new ConnectorTask(connectorName, task, taskNum, totalTaskCount, offsetWriter, offsetCommitPolicy, stopFunction);
        }

        /**
         * Create a {@link Runnable} that polls the given task.
         * 
         * @param connectorTask the task to poll; may not be null
         * @param totalTaskCount the total number of tasks that were configured; must be positive and greater than or equal
         *            to {@code taskNum}
         * @param tasks the collection of the tasks; may not be null
         * @return the runnable; never null
         */
        protected Runnable createTaskRunner(ConnectorTask connectorTask, int totalTaskCount, ConnectorTasks tasks) {
            SourceTask task = connectorTask.task();
            int taskNum = connectorTask.taskNum();
            return () -> {
                try {
                    // And run the task ...
                    logger.trace("Beginning to poll task {} of {} for connector '{}' in engine '{}'", taskNum, totalTaskCount,
                                 connectorName, name());
                    AtomicLong sequence = new AtomicLong(0L);
                    AtomicLong maxSequenceCommitted = new AtomicLong(0L);
                    while (tasks.stillRunning()) {
                        enqueueRecords(task.poll(), connectorTask, connectorName, sequence, maxSequenceCommitted);
                    }
                } catch (InterruptedException t) {
                    Thread.interrupted();
                    logger.trace("Interrupted task {} of {} for connector '{}' in engine '{}'", taskNum, totalTaskCount, connectorName,
                                 name());
                } catch (Throwable t) {
                    // An error occurred while running this task, so make sure the engine is stopped ...
                    logger.debug("Error in task {} of {} for connector '{}' in engine '{}': {}",
                                 taskNum, totalTaskCount, connectorName, name(), t.getMessage(), t);
                    tasks.stopTasks();
                    callback.connectorFailed(connectorName, t.getMessage(), t);
                } finally {
                    // No matter what, make sure that all tasks (including this one) will be stopped exactly one time ...
                    tasks.stopTasks();
                }
            };
        }

        /**
         * Attempt to stop the connector's tasks if they are running and call the supplied function when all tasks have been
         * stopped. If the connector is not currently running, immediately call the supplied function.
         *
         * @param uponCompletion the function to always call when complete, even if the connector is not currently running; may
         *            not be null
         * @return a future that can be called to wait for the connector to complete their shutdown; never null but empty
         *         if no connector exists with the given name
         */
        public synchronized CompletableFuture<Void> stop(Runnable uponCompletion) {
            if (uponCompletion == null) uponCompletion = () -> {};
            ConnectorTasks tasks = this.tasks.get();
            if (tasks == null) {
                // No running connector, so immediately return but always run the function ...
                return CompletableFuture.completedFuture(null).thenRun(uponCompletion);
            }
            logger.trace("Stopping connector '{}' in engine '{}'", connectorName, name());
            return this.tasks.getAndSet(null).stopTasks().thenRun(uponCompletion);
        }

        /**
         * Add to the queue of {@link ChangeEvent}s the list of {@link SourceRecord} change events from the given
         * {@link SourceTask}.
         * 
         * @param records the list of source events; may be null or empty
         * @param connectorTask the connector task that generated these events; may not be null
         * @param connectorName the connector name; may not be null
         * @param sequence a sequence of monotonically increasing long values that can be assigned to each {@link ChangeEvent},
         *            used to ensure that calling {@link ChangeEvent#commit()} out of order does not lose recorded offsets
         * @param maxSequenceCommitted the mutable maximum sequence number that has been committed so far
         * @throws InterruptedException if the calling thread is interrupted while waiting for the events to be enqueued
         */
        protected void enqueueRecords(List<SourceRecord> records, ConnectorTask connectorTask, String connectorName,
                                      AtomicLong sequence, AtomicLong maxSequenceCommitted)
                throws InterruptedException {
            if (records == null) return;
            int numRecords = records.size();
            if (numRecords == 0) return;
            List<ChangeEvent> events = new ArrayList<>(numRecords);
            for (SourceRecord record : records) {
                long sequenceNumber = sequence.incrementAndGet();
                events.add(new SourceChangeEvent(record,
                        () -> connectorTask.commitOffset(record, connectorName, sequenceNumber, maxSequenceCommitted)));
            }
            eventQueue.put(events);
        }
    }

    protected ConnectorContext workerConnectorContext(String connectorName, ConnectorCallback callback) {
        return new ConnectorContext() {
            @Override
            public void requestTaskReconfiguration() {
                // Do nothing ...
            }

            @Override
            public void raiseError(Exception e) {
                callback.connectorFailed(connectorName, e.getMessage(), e);
            }
        };
    }

    @Immutable
    protected static class EmbeddedWorkerConfig extends WorkerConfig {
        private static final ConfigDef CONFIG;

        static {
            ConfigDef config = baseConfigDef();
            Field.group(config, "file", OFFSET_STORAGE_FILE_FILENAME);
            Field.group(config, "kafka", OFFSET_STORAGE_KAFKA_TOPIC);
            CONFIG = config;
        }

        protected EmbeddedWorkerConfig(Map<String, String> props) {
            super(CONFIG, props);
        }
    }

    /**
     * {@link ChangeEvent} implementation that allows for a custom function to be called when this event is
     * {@link ChangeEvent#commit() completed}.
     * 
     * @author Randall Hauch
     */
    @Immutable
    protected static class SourceChangeEvent implements ChangeEvent {
        private final SourceRecord record;
        private final Runnable commitHandler;

        public SourceChangeEvent(SourceRecord record, Runnable commitHandler) {
            assert record != null;
            assert commitHandler != null;
            this.record = record;
            this.commitHandler = commitHandler;
        }

        @Override
        public void commit() {
            commitHandler.run();
        }

        @Override
        public String topic() {
            return record.topic();
        }

        @Override
        public Struct key() {
            return (Struct) record.key();
        }

        @Override
        public Struct value() {
            return (Struct) record.value();
        }

        @Override
        public String toString() {
            return record.toString();
        }
    }
}
