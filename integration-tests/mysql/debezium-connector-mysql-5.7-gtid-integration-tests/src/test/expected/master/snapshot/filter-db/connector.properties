#
# Define the connector
#
name=mysql-conn
connector.class=io.debezium.connector.mysql.MySqlConnector

#
# Define the database connection info.
#
database.hostname=${database.hostname:localhost}
database.port=${database.port:3306}
database.user=snapper
database.password=snapperpass
database.server.id=98001
database.server.name=engineering
#
# SSL connectivity, where mode is "disabled", "preferred", "required", "verify_ca", or "verify_identity"
#
#database.ssl.mode=disabled
#database.ssl.keystore=
#database.ssl.keystore.password=
#database.ssl.truststore=
#database.ssl.truststore.password=

#
# Options for the connector's snapshot of the database upon its first startup,
# where mode is "initial", "when_needed", "schema_only", "never", or "initial_only"
#
#snapshot.mode=initial
#snapshot.minimal.locks=true
#min.row.count.to.stream.results=1000

#
# Include OR exclude specific GTID sources from the GTID set upon connection to the MySQL server.
#
#gtid.source.includes=
#  or
#gtid.source.excludes=

#
# Define the comma-separated fully qualified names (FQNs) of databases and tables to capture
# using either whitelists or blacklists.
#
database.whitelist=regression_test,json_test
#table.whitelist=
#  or
#database.blacklist=
#table.blacklist=
#
#table.ignore.builtin=true

#
# Define the comma-separated fully qualified names (FQNs) of columns to handle in special ways.
#
#column.blacklist=
#column.truncate.to.200.chars=
#column.truncate.to.100.chars=
#column.mask.with.8.chars=
#column.mask.with.12.chars=

#
# Define how decimals and times are to be handled.
#
#decimal.handling.mode=precise
#time.precision.mode=adaptive

#
# Store DDL history of the connector on the file system:
#
database.history=io.debezium.relational.history.FileDatabaseHistory
database.history.file.filename=target/connector-output/${dbz.test.name}.history
#
# or in Kafka
#
#database.history=io.debezium.relational.history.KafkaDatabaseHistory
#database.history.kafka.bootstrap.servers=
#database.history.kafka.topic=
#database.history.kafka.recovery.poll.interval.ms=
#database.history.kafka.recovery.attempts=
#database.history.kafka.consumer.etc=
#database.history.kafka.producer.etc=

#
# Other options for the connector
#
poll.interval.ms=10
#include.schema.changes=true
#max.queue.size=2048
#max.batch.size=1024
#connect.timeout.ms=30000
#connect.keep.alive=true
