ifdef::[community]
[NOTE]
====
This feature is currently in incubating state. The exact semantics, configuration options, and so forth is subject to change in future revisions, based on the feedback we receive.
Please let us know if you encounter any problems while using this extension.
====
endif::[community]

ifdef::[product]
[IMPORTANT]
====
The use of incremental snapshots is a Technology Preview feature.
Technology Preview features are not supported with Red Hat production service-level agreements (SLAs) and might not be functionally complete;
therefore, Red Hat does not recommend implementing any Technology Preview features in production environments.
This Technology Preview feature provides early access to upcoming product innovations, enabling you to test functionality and provide feedback during the development process.
For more information about support scope, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[product]
To provide flexibility in managing snapshots, {prodname} includes a supplementary snapshot mechanism, known as _incremental snapshotting_.
Incremental snapshots rely on the {prodname} mechanism for xref:{link-signalling}#sending-signals-to-a-debezium-connector[sending signals to a {prodname} connector].
ifdef::[community]
Incremental snapshots are based on the link:https://github.com/debezium/debezium-design-documents/blob/main/DDD-3.md[DDD-3] design document.
endif::[community]

In an incremental snapshot, instead of capturing the full state of a database all at once, as in an initial snapshot, {prodname} captures each table in phases, in a series of configurable chunks.
The capture process uses watermarks to track its progress, maintaining a record of each table row that it captures.
This phased approach to capturing data provides the following advantages over the initial snapshot process:

* You can run incremental snapshots in parallel with streamed data capture, instead of postponing streaming until the snapshot completes.
  The connector continues to capture near real-time events from the change log throughout the snapshot process, and neither operation blocks the other.
* If the progress of an incremental snapshot is interrupted, you can resume it without losing any data.
  After the process resumes, the snapshot begins at the point where it stopped, rather than recapturing the table from the beginning.
* You can run an incremental snapshot on demand at any time, and repeat the process as needed do adapt to database updates.
  For example, you might re-run a snapshot to capture new tables and synchronize the Kafka topics to the current state of the database.

[id="{context}-how-debezium-resolves-conflicts-when-it-captures-multiple-events-for-records-that-have-the-same-primary-key"]
.How {prodname} resolves conflicts among records with the same primary key

When you run an incremental snapshot, as {prodname} captures a table chunk, it emits a `READ` event for each captured record.
Meanwhile, alongside the snapshot process, the {prodname} streaming process continues to run, capturing change events as they occur in each source table.
These streaming events are captured as `UPDATE` or `DELETE` events.


//It's not unusual for the connector to emit `UPDATE` or `DELETE` events that modify an existing row before the snapshot process captures the chunk with the `READ` event the represents the row's initial value.
// arrive out of sequence
//events are received out of sequence
Because the incremental snapshot captures tables in chunks, invariably, the streaming process emits `UPDATE` or `DELETE` events that modify a row before the snapshot captures the chunk that includes the `READ` event.
//{prodname} must manage the chronology of `READ` events that originate from the snapshot process alongside of any `UPDATE` or `DELETE` events that originate from the streaming process.
During the window for capturing a table chunk, {prodname} compares the primary keys of the events that it captures through each method.
If the state of a row that the connector captures through the streaming process might conflict with the state that is captured during the snapshot process.

//The default chunk size for incremental snapshots is 1 KB.
//You can configure the chunk size  xref:{context}-property-incremental-snapshot-chunk-size[`incremental.snapshot.chunk.size`].

For a specified chunk, if an `UPDATE` or `DELETE` event exists for a corresponding `READ` event (that is, the events share a primary key), then {prodname}
record in the snapshot to the keys
of the `UPDATE` or `DELETE` event records that the connector obtains by streaming.
Depending on when an incremental snapshot captures the table chunk that includes the "initial" state of a record, the value of the record might already be obsolete.
Updates to a row value might be captured before the snapshot process captures the chunk that includes the record.
tracks the event chronology so that earlier versions of a row do not overwrite later versions.

To maintain the chronology of events when `UPDATE` or `DELETE` events are received out of sequence, {prodname} first records the snapshot `READ` events for each chunk into a buffer.
It then performs a de-duplication step to resolve conflicts among event entries.
The connector repeats the process for each snapshot chunk.

//To determine which version of a record to use in the event of a conflict, the connector compares the primary keys of transactions that occur within a chunk window.
//To resolve conflicts, {prodname} sorts events chronologically.

//* If a `DELETE` event arrives before a corresponding `READ` event, the connector discards the `READ` event from the buffer.
//* If an `UPDATE` event arrives before a corresponding `READ` event, the connector either discards the `READ` event or delivers it with the updated value.

[id="debezium-{context}-triggering-an-incremental-snapshot"]
.Triggering an incremental snapshot

Currently, the only way to perform an incremental snapshot, is to initiate it as an {link-prefix}:#{context}-ad-hoc-snapshot[ad hoc snapshot].
You trigger an incremental snapshot by sending an ad hoc snapshot signal to the signaling table on the source database.
You send the signal by submitting it in a SQL `INSERT` query to the table.
After {prodname} detects the change in the signaling table, it reads the signal, and runs the requested snapshot operation.

The query that you submit specifies the kind of snapshot operation that you want to run the and the tables to include in the snapshot.
Currently, for snapshots operations, the only valid option is the default value, `incremental`.
If you do not specify a value, the connector runs an incremental snapshot.

To specify the tables to include in the snapshot, you create a `data-collections` array that lists the tables, for example, +
`{"data-collections": ["public.MyFirstTable", "public.MySecondTable"]}` +

The `data-collections` array for an incremental snapshot signal has no default value.
If the `data-collections` array  is empty, {prodname} detects that no action is required and does not perform a snapshot.

.Prerequisites

* xref:{link-signalling}#debezium-enabling-signaling"[Signaling is enabled]. +
** A signaling data collection exists on the source database and the connector is configured to capture it.
** The signaling data collection is specified in the xref:{context}-property-signal-data-collection[`signal.data.collection`] property.

.Procedure

. Send a SQL query to add the ad hoc incremental snapshot request to the signaling table:
+
[source,sql,indent=0,subs="+attributes"]
----
INSERT INTO _<signalTable>_ (id, type, data) VALUES (_'<id>'_, _'<snapshotType>'_, '{"data-collections": ["_<tableName>_","_<tableName>_"],"type":"_<snapshotType>_"}');
----
+
For example,
+
[source,sql,indent=0,subs="+attributes"]
----
INSERT INTO myschema.debezium_signal (id, type, data) VALUES('ad-hoc-1', 'execute-snapshot', '{"data-collections": ["schema1.table1", "schema1.table2"],"type":"incremental"}');
----
The values of the `id`,`type`, and `data` parameters in the command correspond to the xref:debezium-signaling-required-structure-of-a-signaling-data-collection[fields of the signaling table].
+
The following table describes the these parameters:
+
.Descriptions of fields in a SQL command for sending an incremental snapshot signal to the signaling table
[cols="1,4",options="header"]
|===
|Value |Description

|`myschema.debezium_signal`
|Specifies the fully-qualified name of the signaling table on the source database

|`ad-hoc-1`
| The `id` parameter specifies an arbitrary string that is assigned as the `id` identifier for the signal request. +
Use this string to identify logging messages to entries in the signaling table.
{prodname} does not use this string.
Rather, during the snapshot, {prodname} generates its own `id` string as a watermarking signal.

|`execute-snapshot`
| Specifies `type` parameter specifies the operation that the signal is intended to trigger. +

|`data-collections`
|A required component of the `data` field of a signal that specifies an array of table names to include in the snapshot. +
The array lists tables by their fully-qualified names, using the same format as you use to specify the name of the connector's signaling table in the xref:{context}-property-signal-data-collection[`signal.data.collection`] configuration property.

|`incremental`
|An optional `type` component of the `data` field of a signal that specifies the kind of snapshot operation to run. +
Currently, the only valid option is the default value, `incremental`. +
Specifying a `type` value in the SQL query that you submit to the signaling table is optional. +
If you do not specify a value, the connector runs an incremental snapshot.
|===

The following example, shows the JSON for an incremental snapshot event that is captured by a connector.

.Example: Incremental snapshot event message
[source,json,index=0]
----
{
    "before":null,
    "after": {
        "pk":"1",
        "value":"New data"
    },
    "source": {
        ...
        "snapshot":"incremental" <1>
    },
    "op":"r", <2>
    "ts_ms":"1620393591654",
    "transaction":null
}
----
[cols="1,1,4",options="header"]
|===
|Item |Field name |Description
|1
|`snapshot`
|Specifies the type of snapshot operation to run. +
Currently, the only valid option is the default value, `incremental`. +
Specifying a `type` value in the SQL query that you submit to the signaling table is optional. +
If you do not specify a value, the connector runs an incremental snapshot.

|2
|`op`
|Specifies the event type. +
The value for snapshot events is `r`, signifying a `READ` operation.

|===
